from typing import List, Optional, Any
from dataclasses import dataclass
import akshare as ak
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


def retry_api_call(func, *args, max_retries=3, delay=1, logger=None, **kwargs):
    """
    APIè°ƒç”¨é‡è¯•æœºåˆ¶
    
    Args:
        func: è¦è°ƒç”¨çš„å‡½æ•°
        *args: å‡½æ•°çš„ä½ç½®å‚æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
        **kwargs: å‡½æ•°çš„å…³é”®å­—å‚æ•°
        
    Returns:
        å‡½æ•°æ‰§è¡Œç»“æœ
        
    Raises:
        Exception: å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€æ¬¡çš„å¼‚å¸¸
    """
    last_exception = None
    
    def log_info(msg):
        if logger:
            logger.info(msg)
        else:
            print(f"[INFO] {msg}")
    
    def log_warning(msg):
        if logger:
            logger.warning(msg)
        else:
            print(f"[WARNING] {msg}")
    
    def log_error(msg):
        if logger:
            logger.error(msg)
        else:
            print(f"[ERROR] {msg}")
    
    for attempt in range(max_retries + 1):  # +1 å› ä¸ºç¬¬ä¸€æ¬¡ä¸ç®—é‡è¯•
        try:
            result = func(*args, **kwargs)
            if attempt > 0:
                log_info(f"APIè°ƒç”¨æˆåŠŸï¼ˆç¬¬{attempt}æ¬¡é‡è¯•ï¼‰")
            return result
        except Exception as e:
            last_exception = e
            if attempt < max_retries:
                log_warning(f"APIè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼‰ï¼Œ{delay}ç§’åé‡è¯•: {str(e)}")
                time.sleep(delay)
            else:
                log_error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries}): {str(e)}")
    
    raise last_exception


@dataclass
class Input:
    """è¾“å…¥å‚æ•°"""
    pass  # å½“å‰ä½¿ç”¨ç¡¬ç¼–ç å‚æ•°ï¼Œæš‚ä¸éœ€è¦è¾“å…¥å‚æ•°


@dataclass
class FundData:
    """åŸºé‡‘æ•°æ®"""
    code: str  # åŸºé‡‘ä»£ç 
    name: str  # åŸºé‡‘åç§°
    premium_rate: float  # æº¢ä»·ç‡ï¼ˆ%ï¼‰
    nav_date: str  # å‡€å€¼æ—¥æœŸ


class Output:
    """è¾“å‡ºç»“æœ - æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    def __init__(self, content: str):
        self.content = content


class Args:
    def __init__(self, input_data, logger):
        self.input = input_data
        self.logger = logger


def handler(args: Args) -> Output:
    """
    è·å–LOFåŸºé‡‘æº¢ä»·ç‡æ•°æ®
    
    Args:
        args: åŒ…å«è¾“å…¥å‚æ•°å’Œæ—¥å¿—å®ä¾‹çš„å‚æ•°å¯¹è±¡
        
    Returns:
        åŒ…å«æ‰€æœ‰åŸºé‡‘æ•°æ®å’Œåˆ†æç»“æœçš„è¾“å‡ºå¯¹è±¡
    """
    try:
        # ç¡¬ç¼–ç å‚æ•°é…ç½®
        max_funds = None
        max_workers = 1
        watch_list = ['161116', '160723', '161129']  # ç‰¹åˆ«å…³æ³¨çš„åŸºé‡‘åˆ—è¡¨
        
        args.logger.info(f"ä½¿ç”¨ç¡¬ç¼–ç å‚æ•°: max_funds={max_funds}, max_workers={max_workers}, watch_list={watch_list}")
        
        args.logger.info("å¼€å§‹è·å–LOFåŸºé‡‘æ•°æ®...")
        
        # è·å–LOFåŸºé‡‘æº¢ä»·ç‡æ•°æ®
        # ä½¿ç”¨AkShareçš„fund_lof_spot_emæ¥å£è·å–LOFåŸºé‡‘å®æ—¶æ•°æ®
        try:
            df = retry_api_call(ak.fund_lof_spot_em, max_retries=3, delay=2, logger=args.logger)
            args.logger.info(f"æˆåŠŸè·å–LOFåŸºé‡‘æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
        except Exception as e:
            error_msg = f"è·å–LOFåŸºé‡‘åˆ—è¡¨å¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: {str(e)}"
            args.logger.error(error_msg)
            return Output(f"âŒ é”™è¯¯ï¼š{error_msg}")
        
        # æ•°æ®å¤„ç†å’Œç­›é€‰
        if df.empty:
            args.logger.warning("è·å–åˆ°çš„æ•°æ®ä¸ºç©º")
            return Output("âŒ é”™è¯¯ï¼šæœªè·å–åˆ°ä»»ä½•LOFåŸºé‡‘æ•°æ®")
        
        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·']
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            error_msg = f"æœªæ‰¾åˆ°å¿…è¦çš„æ•°æ®åˆ—: {missing_cols}"
            args.logger.error(error_msg)
            return Output(f"âŒ é”™è¯¯ï¼š{error_msg}")
        
        args.logger.info("æ‰¾åˆ°æ‰€æœ‰å¿…è¦åˆ—ï¼šä»£ç ã€åç§°ã€æœ€æ–°ä»·")
        
        # ç­›é€‰æœ‰æ•ˆæ•°æ®
        args.logger.info(f"ç­›é€‰å‰æ•°æ®è¡Œæ•°: {len(df)}")
        df = df.dropna(subset=['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·'])
        args.logger.info(f"å»é™¤ç©ºå€¼åæ•°æ®è¡Œæ•°: {len(df)}")
        
        if len(df) == 0:
            args.logger.warning("å¤„ç†åæ•°æ®ä¸ºç©º")
            return Output("âŒ é”™è¯¯ï¼šç­›é€‰åæ— æœ‰æ•ˆåŸºé‡‘æ•°æ®")
        
        # æ ¹æ®è¾“å…¥å‚æ•°é™åˆ¶å¤„ç†çš„åŸºé‡‘æ•°é‡
        if max_funds and len(df) > max_funds:
            args.logger.info(f"é™åˆ¶å¤„ç†å‰ {max_funds} åªåŸºé‡‘")
            df = df.head(max_funds)
        
        # æ™ºèƒ½é¢„ç­›é€‰ï¼Œå‡å°‘APIè°ƒç”¨æ¬¡æ•°
        def should_skip_fund(fund_code, fund_name, market_price):
            """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸåªåŸºé‡‘ï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰"""
            
            # 1. ä»·æ ¼å¼‚å¸¸ç­›é€‰
            if market_price <= 0 or market_price > 100:
                return True, "ä»·æ ¼å¼‚å¸¸"
            
            # 2. åŸºé‡‘ç±»å‹ç­›é€‰ï¼ˆè¿™äº›ç±»å‹å¾ˆå°‘æœ‰æº¢ä»·ï¼‰
            skip_keywords = ['å€ºåˆ¸', 'è´§å¸', 'çŸ­å€º', 'çº¯å€º', 'ä¸­å€º', 'å›½å€º', 'ä¿¡ç”¨å€º', 
                           'å¯è½¬å€º', 'ä¼ä¸šå€º', 'æ”¿åºœå€º', 'åŒä¸šå­˜å•']
            if any(keyword in fund_name for keyword in skip_keywords):
                return True, "å€ºåˆ¸/è´§å¸ç±»åŸºé‡‘"
            
            # 3. åŸºé‡‘ä»£ç è§„å¾‹ç­›é€‰
            if fund_code.startswith('511'):  # è´§å¸ETFé€šå¸¸åœ¨LOFåˆ—è¡¨ä¸­ä½†å¾ˆå°‘æº¢ä»·
                return True, "è´§å¸ETF"
            
            # 4. ä»·æ ¼è¿‡ä½ç­›é€‰ï¼ˆé€šå¸¸å‡€å€¼æ¥è¿‘1ï¼Œä»·æ ¼è¿‡ä½å¯èƒ½æ˜¯æ•°æ®é—®é¢˜ï¼‰
            if market_price < 0.5:
                return True, "ä»·æ ¼è¿‡ä½"
                
            return False, ""
        
        # åº”ç”¨é¢„ç­›é€‰
        args.logger.info("å¼€å§‹æ™ºèƒ½é¢„ç­›é€‰ï¼Œå‡å°‘APIè°ƒç”¨...")
        original_count = len(df)
        filtered_funds = []
        skipped_count = 0
        skip_reasons = {}
        
        for _, row in df.iterrows():
            fund_code = str(row['ä»£ç '])
            fund_name = str(row['åç§°'])
            market_price = float(row['æœ€æ–°ä»·'])
            
            should_skip, reason = should_skip_fund(fund_code, fund_name, market_price)
            if should_skip:
                skipped_count += 1
                skip_reasons[reason] = skip_reasons.get(reason, 0) + 1
            else:
                filtered_funds.append((fund_code, fund_name, market_price))
        
        args.logger.info(f"é¢„ç­›é€‰å®Œæˆ: {original_count} -> {len(filtered_funds)} åªåŸºé‡‘ï¼ˆè·³è¿‡ {skipped_count} åªï¼‰")
        for reason, count in skip_reasons.items():
            args.logger.info(f"  è·³è¿‡åŸå›  - {reason}: {count} åª")
        
        if not filtered_funds:
            args.logger.warning("é¢„ç­›é€‰åæ— åŸºé‡‘éœ€è¦å¤„ç†")
            return Output("âš ï¸ è­¦å‘Šï¼šé¢„ç­›é€‰åæ²¡æœ‰éœ€è¦å¤„ç†çš„åŸºé‡‘")
        
        # ä¼˜å…ˆçº§æ’åºï¼šä¼˜å…ˆå¤„ç†å¯èƒ½æœ‰æº¢ä»·çš„åŸºé‡‘ç±»å‹
        priority_keywords = ['åŸæ²¹', 'é»„é‡‘', 'å•†å“', 'æµ·å¤–', 'æ¸¯è‚¡', 'ç¾è‚¡', 'QDII', 
                           'çŸ³æ²¹', 'è´µé‡‘å±', 'æœ‰è‰²', 'ç…¤ç‚­', 'é’¢é“']
        priority_funds = []
        normal_funds = []
        
        for fund_info in filtered_funds:
            fund_code, fund_name, market_price = fund_info
            if any(keyword in fund_name for keyword in priority_keywords):
                priority_funds.append(fund_info)
            else:
                normal_funds.append(fund_info)
        
        # é‡æ–°æ’åºï¼šä¼˜å…ˆçº§åŸºé‡‘åœ¨å‰
        fund_list = priority_funds + normal_funds
        args.logger.info(f"ä¼˜å…ˆçº§æ’åº: é«˜ä¼˜å…ˆçº§ {len(priority_funds)} åªï¼Œæ™®é€š {len(normal_funds)} åª")

        # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘è·å–å‡€å€¼æ•°æ®
        args.logger.info(f"å¼€å§‹å¹¶å‘è·å– {len(fund_list)} åªåŸºé‡‘çš„å‡€å€¼æ•°æ®...")
        start_time = time.time()
        
        def get_fund_premium_rate(fund_info):
            """è·å–å•åªåŸºé‡‘çš„æº¢ä»·ç‡"""
            fund_code, fund_name, market_price = fund_info
            try:
                # è·å–åŸºé‡‘å‡€å€¼æ•°æ®
                nav_df = retry_api_call(
                    ak.fund_open_fund_info_em, 
                    symbol=fund_code, 
                    indicator="å•ä½å‡€å€¼èµ°åŠ¿",
                    max_retries=3,
                    delay=1,
                    logger=args.logger
                )
                
                if not nav_df.empty:
                    # è·å–æœ€æ–°å‡€å€¼ï¼ˆæœ€åä¸€è¡Œæ•°æ®ï¼‰
                    latest_nav = float(nav_df.iloc[-1]['å•ä½å‡€å€¼'])
                    nav_date = nav_df.iloc[-1]['å‡€å€¼æ—¥æœŸ']
                    
                    # è®¡ç®—æº¢ä»·ç‡ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰
                    premium_rate = round((market_price - latest_nav) / latest_nav * 100, 2)
                    
                    return {
                        'success': True,
                        'data': FundData(
                            code=fund_code,
                            name=fund_name,
                            premium_rate=premium_rate,
                            nav_date=nav_date
                        ),
                        'details': f"å¸‚ä»·={market_price:.4f}, å‡€å€¼={latest_nav:.4f}({nav_date}), æº¢ä»·ç‡={premium_rate:.2f}%"
                    }
                else:
                    return {'success': False, 'error': 'å‡€å€¼æ•°æ®ä¸ºç©º', 'code': fund_code, 'name': fund_name}
                    
            except Exception as e:
                return {'success': False, 'error': f'è·å–å‡€å€¼å¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: {str(e)}', 'code': fund_code, 'name': fund_name}
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        results = []
        successful_count = 0
        failed_count = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_fund = {executor.submit(get_fund_premium_rate, fund_info): fund_info[0] for fund_info in fund_list}
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_fund):
                result = future.result()
                if result['success']:
                    results.append(result['data'])
                    successful_count += 1
                    args.logger.info(f"âœ“ {result['data'].code} {result['data'].name}: {result['details']}")
                else:
                    failed_count += 1
                    args.logger.warning(f"âœ— {result['code']} {result['name']}: {result['error']}")
        
        end_time = time.time()
        args.logger.info(f"å‡€å€¼è·å–å®Œæˆ: æˆåŠŸ {successful_count} åªï¼Œå¤±è´¥ {failed_count} åªï¼Œè€—æ—¶ {end_time - start_time:.1f} ç§’")
        
        if not results:
            args.logger.warning("æ²¡æœ‰æˆåŠŸè·å–åˆ°ä»»ä½•åŸºé‡‘çš„æº¢ä»·ç‡æ•°æ®")
            return Output("âŒ é”™è¯¯ï¼šæœªèƒ½è·å–åˆ°ä»»ä½•åŸºé‡‘çš„æº¢ä»·ç‡æ•°æ®")
        
        # è¿‡æ»¤æ‰æº¢ä»·ç‡å°äº0çš„åŸºé‡‘ï¼ˆåªä¿ç•™æœ‰æº¢ä»·çš„åŸºé‡‘ï¼‰
        premium_results = [result for result in results if result.premium_rate >= 0]
        args.logger.info(f"è¿‡æ»¤å‰: {len(results)} åªåŸºé‡‘ï¼Œè¿‡æ»¤å: {len(premium_results)} åªåŸºé‡‘ï¼ˆåªä¿ç•™æº¢ä»·ç‡>=0çš„åŸºé‡‘ï¼‰")
        
        if not premium_results:
            args.logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æº¢ä»·çš„åŸºé‡‘")
            return Output("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æº¢ä»·çš„åŸºé‡‘")
        
        # æŒ‰æº¢ä»·ç‡ä»é«˜åˆ°ä½æ’åº
        premium_results.sort(key=lambda x: x.premium_rate, reverse=True)
        args.logger.info(f"æ’åºå®Œæˆï¼Œæº¢ä»·ç‡èŒƒå›´: {premium_results[-1].premium_rate:.2f}% ~ {premium_results[0].premium_rate:.2f}%")
        
        # å¤„ç†ç‰¹åˆ«å…³æ³¨åˆ—è¡¨ï¼ˆåªåŒ…å«æœ‰æº¢ä»·çš„åŸºé‡‘ï¼‰
        watch_results = []
        if watch_list:
            args.logger.info("å¤„ç†ç‰¹åˆ«å…³æ³¨åŸºé‡‘åˆ—è¡¨...")
            for watch_code in watch_list:
                # åœ¨æº¢ä»·ç»“æœä¸­æŸ¥æ‰¾ç‰¹åˆ«å…³æ³¨çš„åŸºé‡‘
                found = False
                for result in premium_results:
                    if result.code == watch_code:
                        watch_results.append(result)
                        args.logger.info(f"âœ“ {result.code} {result.name}: æº¢ä»·ç‡ {result.premium_rate:.2f}%")
                        found = True
                        break
                
                if not found:
                    # æ£€æŸ¥æ˜¯å¦åœ¨åŸå§‹ç»“æœä¸­ä½†æ˜¯æ˜¯æŠ˜ä»·çš„
                    is_discount = any(r.code == watch_code and r.premium_rate < 0 for r in results)
                    if is_discount:
                        args.logger.info(f"âœ— {watch_code}: åŸºé‡‘ä¸ºæŠ˜ä»·ï¼Œä¸åœ¨æº¢ä»·åˆ—è¡¨ä¸­")
                    else:
                        args.logger.warning(f"âœ— {watch_code}: æœªæ‰¾åˆ°æ•°æ®ï¼ˆå¯èƒ½è·å–å¤±è´¥ï¼‰")
        
        # æ„é€ æ ¼å¼åŒ–çš„è¾“å‡ºå­—ç¬¦ä¸²
        from datetime import datetime
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        output_lines = []
        output_lines.append(f"ğŸ“… è®¡ç®—æ‰§è¡Œæ—¶é—´ï¼š{current_time}")
        output_lines.append(f"ğŸ“ˆ æœ‰æº¢ä»·åŸºé‡‘ï¼š{len(premium_results)} åªï¼Œæ•°æ®æˆåŠŸç‡ï¼š{successful_count}/{successful_count + failed_count} ({successful_count/(successful_count + failed_count)*100:.1f}%)")
        
        if premium_results:
            # æ‰¾åˆ°æœ€å¸¸è§çš„å‡€å€¼æ—¥æœŸï¼ˆå¤§å¤šæ•°åŸºé‡‘çš„å‡€å€¼æ—¥æœŸï¼‰
            nav_dates = [fund.nav_date for fund in premium_results]
            most_common_date = max(set(nav_dates), key=nav_dates.count)
            output_lines.append(f"ğŸ“… æº¢ä»·ç‡æ‰€ä»£è¡¨çš„å®é™…æ—¥æœŸï¼ˆT-1ï¼‰: {most_common_date}")
        
        # ç‰¹åˆ«å…³æ³¨çš„åŸºé‡‘
        if watch_results:
            output_lines.append("")
            output_lines.append("ğŸ”¥ ç‰¹åˆ«å…³æ³¨:")
            for i, fund in enumerate(watch_results, 1):
                output_lines.append(f"  {i:2d}. {fund.code} {fund.name} æº¢ä»·ç‡: {fund.premium_rate:.2f}%")
        elif watch_list:
            output_lines.append("")
            output_lines.append("ğŸ”¥ ç‰¹åˆ«å…³æ³¨:")
            output_lines.append("  âš ï¸ å…³æ³¨çš„åŸºé‡‘æš‚æ— æº¢ä»·æˆ–è·å–å¤±è´¥")
        
        # å‰5åªæº¢ä»·ç‡æœ€é«˜çš„åŸºé‡‘
        if premium_results:
            output_lines.append("")
            output_lines.append("ğŸ“ˆ æº¢ä»·ç‡æœ€é«˜çš„LOFåŸºé‡‘ï¼ˆTOP5ï¼‰:")
            top_5 = premium_results[:5]
            for i, fund in enumerate(top_5, 1):
                output_lines.append(f"  {i:2d}. {fund.code} {fund.name} æº¢ä»·ç‡: {fund.premium_rate:.2f}%")
        
        # æ„é€ æœ€ç»ˆè¾“å‡º
        result_content = "\n".join(output_lines)
        args.logger.info(f"ç”ŸæˆæŠ¥å‘Šå®Œæˆï¼Œå…±{len(premium_results)}åªæœ‰æº¢ä»·åŸºé‡‘")
        
        return Output(result_content)
        
    except Exception as e:
        error_message = f"è·å–LOFåŸºé‡‘æº¢ä»·ç‡æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        args.logger.error(error_message)
        import traceback
        args.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        return Output(f"âŒ ç³»ç»Ÿé”™è¯¯ï¼š{error_message}")

# æœ¬åœ°æµ‹è¯•ç”¨å‡½æ•°ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼Œéƒ¨ç½²æ—¶ä¸ä¼šæ‰§è¡Œï¼‰
if __name__ == "__main__":
    class MockLogger:
        def info(self, msg): print(f"[INFO] {msg}")
        def warning(self, msg): print(f"[WARNING] {msg}")
        def error(self, msg): print(f"[ERROR] {msg}")
    
    # æ¨¡æ‹Ÿ serverless ç¯å¢ƒ - è¾“å…¥å‚æ•°ç°åœ¨æ˜¯ç¡¬ç¼–ç çš„ï¼Œæ‰€ä»¥å¯ä»¥ä¼ å…¥ä»»æ„å€¼
    mock_args = Args("{}", MockLogger())  # æ¨¡æ‹Ÿç©ºJSONè¾“å…¥
    
    print("LOFåŸºé‡‘æº¢ä»·ç‡è®¡ç®—å·¥å…·ï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰")
    
    result = handler(mock_args)
    
    print(f"\n=== æ‰§è¡Œç»“æœ ===")
    print(result.content)
